{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Models and Axioms\n",
    "\n",
    "Many events cant be predicted with total certainty. The best we say is how **likely** there are to happen using the idea of probability. Probability can be thought as a mathematical framework for reasoning about uncertainty and developing approaches to inference problem.\n",
    "\n",
    "## Probabilities Model\n",
    "\n",
    "A probabilities model is a mathematical description of a random phenomenon. It is defined by its **sample space**, **events** within the sample space, and **probabilities** associated with each event.\n",
    "\n",
    "The sample space ( $S$ or $\\Omega$) for a probability model is the set of all possible outcomes. \n",
    "\n",
    "An event $A$ is a subset of the sample space $S$.\n",
    "\n",
    "A probability is a numerical value assigned to a given event $A$. The probability of an event is written $P(A)$, and describes the long-run relative frequency of the event. Probability is assigned using a probability law, which is defined according to the experiment.\n",
    "\n",
    "Every probabilistic model involves an underlying process, called the **experiment**. An experiment will produce exactly one and only one element of several possible outcomes.\n",
    "\n",
    "## Sample Space\n",
    "\n",
    "Sample space is a list (set) of all possible outcomes for an experiment. Sample is denoted by capital $S$ or $\\Omega$. Example of sample space for experiment of flipping a coin onces is ${H, T}$ which was two possible outcomes, either flip will result in heads ($H$) or tails $(T)$.\n",
    "\n",
    "### Rules for sample space\n",
    "\n",
    "Not all sets can be termed as sample space. For a set to be consider as sample space it must obey the following rules.\n",
    "\n",
    "#### Mutually Exclusive\n",
    "\n",
    "Every outcome (element) in the sample space set must be mutually exclusive. Which means when are experiment is perform the outcome must belong to one and only one element of the set, no two outcomes of the set can occur at a same time.\n",
    "\n",
    "#### Collectively Exhaustive\n",
    "\n",
    "Sample set must contains every possible outcome of an experiment. There should not be any outcome of an experiment which does not belongs to sample space.\n",
    "\n",
    "### Representation\n",
    "\n",
    "There are multiple ways to represent sample space.\n",
    "\n",
    "#### List of outcomes\n",
    "\n",
    "One way if representing sample space is to list all possible outcomes for the experiment.\n",
    "\n",
    "For example, suppose our experiment involves flipping a coin twice. Then our sample space will be as follows.\n",
    "\n",
    "$$\n",
    "S = \\Omega = \\{ HH, HT, TH, TT \\}\n",
    "$$\n",
    "\n",
    "#### Tree based sequential description\n",
    "\n",
    "Another way of representing sample space is to sequentially represent events in the sample space as branches of a tree and thus each branch represent a possible outcome of an experiment and the leaf of the tree represents the sample space for the experiment.\n",
    "\n",
    "For example, suppose our experiment involves flipping a coin twice. Then our sample space will be as follows.\n",
    "\n",
    "![Tree Sample Space](/static/img/notes/mathematics/intro-probability/sample_space_tree.png)\n",
    "\n",
    "### Discrete Sample Space\n",
    "\n",
    "A sample space is said to be discrete sample space if the sample space ($\\Omega$) is a finite set or countable infinity.\n",
    "\n",
    "Example of discrete sample space are flipping a coin, rolling a dice etc.\n",
    "\n",
    "### Continuous Sample Space\n",
    "\n",
    "Sample space is called as continuous if the sample space ($\\Omega$) contains uncountable infinite set of possible outcomes.\n",
    "\n",
    "Consider the example below, let see our experiment in to see the where the dart lands in the area marked by the rectangle at $x=1$ and $y=1$. \n",
    "\n",
    "![Continuous Sample Space](/static/img/notes/mathematics/intro-probability/continous_sample_space.png)\n",
    "\n",
    "Here our sample space is all the infinite set of rational points in the square reason. So our sample space is defined as follows,\n",
    "\n",
    "$$\n",
    "S = \\Omega = \\{ (x, y) | 0 \\leqslant x, y \\leqslant 1 \\}\n",
    "$$\n",
    "\n",
    "**Note:**\n",
    "\n",
    "Continuous sample spaces are interesting because we have a sample space with infinite outcomes in it. In the above example, the probability of hitting a point let say $(\\frac{1}{2}, \\frac{1}{3})$ with infinite precession is **zero**. But the collective probability is $1$, because the dart will definitely land somewhere in the 1 by 1 area. So to overcome this when we calculate probability we calculate probability of **event**, which is collection of many individual point (subset of sample space) instead of calculating probability of individual point. Even in discrete case we work with events, to be consistent.\n",
    "\n",
    "## Probability Axioms\n",
    "\n",
    "Every probabilistic model must follow these three rules called the axioms of probability.\n",
    "\n",
    "### Nonnegativity\n",
    "\n",
    "This axiom states that probability of an event cannot be negative.\n",
    "\n",
    "Let $A$ be any event,\n",
    "\n",
    "$$\n",
    "P(A) \\geqslant 0\n",
    "$$\n",
    "\n",
    "### Normalization\n",
    "\n",
    "Normalization axiom states that the probability of sample space is always $1$\n",
    "\n",
    "$$\n",
    "P(\\Omega) = 1\n",
    "$$\n",
    "\n",
    "### Additivity\n",
    "\n",
    "Additivity axioms states that the probability of two event occurring together is sum of there individual probability.\n",
    "\n",
    "Let $A$ and $B$ be two events,\n",
    "\n",
    "$$\n",
    "\\text{If} A \\cap B \\ne \\phi \\; \\text{then} \\; P(A \\cup B) = P(A) + P(B)\n",
    "$$\n",
    "\n",
    "\n",
    "## Uniform Law\n",
    "\n",
    "### Discrete Case\n",
    "\n",
    "Let $X$ and $Y$ be two event of rolling a fair die. Then we can find out probabilities as follows.\n",
    "\n",
    "The probability of $X = 1 \\; \\text{and} \\; Y = 1$ or $X = 1 \\; \\text{and} \\; Y = 2$ is ,\n",
    "\n",
    "Le $A$ be the event where $X=1 \\; \\text{and} \\; Y=1$ and $B$ be the event where $X=1 \\; \\text{and} \\; Y=2$, then \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(A \\cup B) &= P(A) + P(B) \\tag{Additivity} \\\\\n",
    "&= \\frac{1}{36} + \\frac{1}{36} \\tag{Each outcome is equally likely} \\\\\n",
    "&= \\frac{2}{36} \\\\\n",
    "&= \\frac{1}{18} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The probability of $X = 1 \\; \\text{and} \\; Y = 1$ or $X = 1 \\; \\text{and} \\; Y = 2$ is $\\frac{1}{18}$.\n",
    "\n",
    "Another way of looking at the problem is listing down all the possible outcomes (Sample Space) and then counting the number of outcome we are interested in. \n",
    "\n",
    "So our sample space would be,\n",
    "\n",
    "$$\n",
    "S = \\Omega = \\{ (1,1), (1,2), (1,3), ....., (6,6) \\}\n",
    "$$\n",
    "\n",
    "In that we are interested in two outcomes, one is $(1, 1)$ and $(1,2)$. So the probability will be number of interested event upon the total number of possible events which is $\\frac{2}{36}$ or $\\frac{1}{18}$. This is called the **Discrete uniform law**. \n",
    "\n",
    "It states that, If all outcomes are equally likely and let $A$ be some event. Then\n",
    "\n",
    "$$\n",
    "P(A) = \\frac{\\text{Number of element of A}}{\\text{total number of element in sample space}}\n",
    "$$\n",
    "\n",
    "\n",
    "### Continuous Case\n",
    "\n",
    "For the case of continuous sample space the uniform law is simply the area under the event. \n",
    "\n",
    "For example.\n",
    "\n",
    "![Continuous Sample Space Example](/static/img/notes/mathematics/intro-probability/continous_sample_space_example.png)\n",
    "\n",
    "To calculate the probability of shaded reason where $X \\leqslant \\frac{1}{2}$ and $Y \\leqslant \\frac{1}{2}$. We calculate the area of the shaded reason, generally using integrals. But here since it forms a simple triangle we can use the area of triangle formula to calculate the area. So the probability of the event is,\n",
    "\n",
    "$$\n",
    "P(A) = \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{2} = \\frac{1}{8}\n",
    "$$\n",
    "\n",
    "\n",
    "## Countable Additivity Axiom\n",
    "\n",
    "We can extend the additivity axiom to countable infinite set. As follows,\n",
    "\n",
    "Suppose we have countable infinite sample space $S$ and let $A_1, A_2, A_3, ....$ are disjoint events, then.\n",
    "\n",
    "$$\n",
    "P(A_1 \\cup A_2 \\cup A_3 \\cup ... ) = P(A_1) + P(A_2) + P(A_3) + ...\n",
    "$$\n",
    "\n",
    "For example.\n",
    "\n",
    "Let our experiment be flipping coin until we get a head. So our sample space becomes the number of flips (Countable Infinity).\n",
    "\n",
    "$$\n",
    "S = \\Omega = \\{1, 2, 3, ... \\}\n",
    "$$\n",
    "\n",
    "Now the probability if each event is a simple geometric series.\n",
    "\n",
    "$$\n",
    "P(1) = \\frac{1}{2}, P(2) = \\frac{1}{4}, P(3) = \\frac{1}{8}, ...\n",
    "$$\n",
    "\n",
    "Now lets say we want to find out probability of event where number of tosses are even. Thus\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P({2, 4, ...}) &= P(2) + P(4) + ... \\tag{Countable Additivity Axiom} \\\\\n",
    "&= \\frac{1}{2^2} + \\frac{1}{2^4} + ... \\\\\n",
    "&= \\frac{1}{3} \\tag{Sum of geometric progression}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Thus there is $\\frac{1}{3}$ or $33%$ probability there heads will turn up in even number of chances\n",
    "\n",
    "# Conditional Probability\n",
    "\n",
    "Conditional probability is used to calculate the probability of two dependent events. For example consider the following sample space.\n",
    "\n",
    "![Conditional Probability](/static/img/notes/mathematics/intro-probability/conditional_probability.png)\n",
    "\n",
    "As we can see there are two events A and B. With probabilities gives in the diagram. Finding probability of individual event is matter of adding the number for example,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(A) &= \\frac{3}{6} + \\frac{2}{6} = \\frac{5}{6} \\\\\n",
    "P(B) &= \\frac{2}{6} + \\frac{1}{6} = \\frac{3}{6}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "But suppose we have told that event $B$ has occurred and now what is the probability of event $A$ occurring. Such probabilities where we know a certain event has happened and we want to find out the probability of another event based on our new believes we used conditional probability return as $P(A|B)$, read as *\"Probability of event A given that B occurred\"*.\n",
    "\n",
    "Intuitively, if we consider the above sample space. We know for sure that event $B$ has occurred so we can assume event $B$ as our new sample space and then finding out what is the probability of event $A$. As seen from the diagram, if event $B$ becomes our new sample space then $P(B) =  1$. But we must keep the ratio between the parts of event $B$ consistent. As we can say from the diagram event $B$ is divided into a ratio of $2:1$ so if $P(B) = 1$ and we keep the ratio consistent, then event $B$ must be divided into two parts of $\\frac{2}{3}$ and $\\frac{1}{3}$. So the probability of event $A$ occurring given that $B$ has occurred is $\\frac{2}{3}$.\n",
    "\n",
    "More formally, we can define conditional probability as follows.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(A|B) &= \\frac{P(A \\cup B)}{P(B)} \\tag{Assuming P(B) is not zero}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "So in our above example.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(A|B) &= \\frac{P(A \\cup B)}{P(B)} \\\\\n",
    "&= \\frac{\\frac{2}{6}}{\\frac{3}{6}} \\\\\n",
    "P(A |B) &= \\frac{2}{3}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## Multiplication Rule\n",
    "\n",
    "Now let's consider following example.\n",
    "\n",
    "![Multiplication Rule Example](/static/img/notes/mathematics/intro-probability/multiplication_rule_example.png)\n",
    "\n",
    "\n",
    "Suppose we have a radar installed in our premises which decided if an airplane is flying above the ground. Now consider two event.\n",
    "\n",
    "Event $A$ is airplane is flying above.\n",
    "\n",
    "Event $B$ is something is registered on the radar.\n",
    "\n",
    "And the probability of combination of each events is given in the diagram above.\n",
    "\n",
    "Now suppose we are to find following probabilities. 1) $P(A \\cap B)$: Probability of event is flying above and radar has registered something. 2) $P(B)$: Probability of something is registered on the radar both if actual plan is detected and false alarm. 3) $P(A|B)$: Probability of air plane is actually flying above the ground, given that something is registered on the radar.\n",
    "\n",
    "For first case, $P(A \\cap B)$ is probability of event $A$ occurring and probability of event $B$ occurring together. We can find it using the definition of condition probability which is $P(B|A) = \\frac{P(B \\cap A)}{P(A)} = \\frac{P(A \\cap B)}{P(A)}$ because $A \\cap B = B \\cap A$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(A \\cap B) &= P(B|A) \\; P(A) \\\\\n",
    "&= 0.99 * 0.05 \\\\\n",
    "P(A \\cap B) &= 0.0495\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "For the second case $P(B)$ we have two events where $B$ will happen $P(B|A)$ or $P(B|A^c)$. So the total probability of $B$ is addition of two properties by additivity axiom.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(B) &= P(B|A) + P(B|A^c) \\\\\n",
    "&= 0.05 * 0.99 + 0.95 * 0.10 \\tag{calculated as same as first case} \\\\ \n",
    "P(B) &= 0.1445\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Now for the last case $P(A|B)$ is start forward.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(A|B) &= \\frac{P(A \\cap B)}{P(B)} \\\\\n",
    "&= \\frac{0.0495}{0.1445} \\\\\n",
    "P(A|B) &= 0.342\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We can generalize this calculation as follows. Suppose we have probability model as such.\n",
    "\n",
    "![Multiplication Rule Example](/static/img/notes/mathematics/intro-probability/multiplication_rule_general.png)\n",
    "\n",
    "Then finding probability of any leaf node event is as simple as multiplying each each probability on the way from the root to the node. For example,\n",
    "\n",
    "$$\n",
    "P(A \\cap B \\cap C) = P(A) \\; P(B|A) \\; P(C |A \\cap B) \n",
    "$$\n",
    "\n",
    "And this is called the multiplication rule, we can even formally derive this rule.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(A \\cap B \\cap C) &= P(A \\cap B) \\; P(C| A \\cap B) \\tag{conditional probability definition} \\\\\n",
    "P(A \\cap B \\cap C) &= P(A) \\; P(B|A) \\; P(C | A \\cap B) \\tag{conditional probability definition}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## Total Probability Theorem\n",
    "\n",
    "Suppose we have following sample space with event $B$ divided into different parts of sample space, namely $A1, A2$ and $A3$. And we want to find the probability of event $B$.\n",
    "\n",
    "![Total Probability Theorem](/static/img/notes/mathematics/intro-probability/total_probability_example.png)\n",
    "\n",
    "We can compute the probability of event B by taking condition probability of each event with respect to $B$ and then taking weighted average for each probability. So that event (for example $A1$) which is more likely to occur get more probability. Thus total probability states the following.\n",
    "\n",
    "For every partition $A_i$ we do the following, (in the above case three)\n",
    "\n",
    "$$\n",
    "P(B) = P(A_1) \\; P(B|A_1) \\\\\n",
    "    + P(A_2) \\; P(B | A_2) \\\\\n",
    "    + P(A_3) \\; P(B | A_3)\n",
    "$$\n",
    "\n",
    "## Bayes Rule\n",
    "\n",
    "Our condition probability theorem and rules were based on initial believes. But using Bayes rule we can inference about an event. For example in the same diagram above if we know that event $B$ has occurred what is the probability that event $A_1$ has occurred, or in other words what is $P(A_1 | B)$\n",
    "\n",
    "We can derive it as follows\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(A_1 | B) &= \\frac{P(A_1 \\cap B)}{P(B)} \\tag{by definition} \\\\\n",
    "&= \\frac{P(A_1) P(A_1 | B)}{P(B)} \\tag{Multiplication Rule} \\\\\n",
    "&= \\frac{P(A_1) P(A_1 | B)}{\\sum_{i=N} P(A_i) \\; P(B | A_i)} \\tag{total probability theorem} \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "thus we can generalize this formula for any $A_i$ as follows,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(A_i | B) &= \\frac{P(A_i) P(A_i | B)}{\\sum_{j=N} P(A_j) \\; P(B | A_j)} \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "thus giving us the Bayes rule, which is foundation for inference probability.\n",
    "\n",
    "# Independence\n",
    "\n",
    "Two events are said to be independent if occurring of one event doesn't change our believes for the other event. Suppose there are two events $A$ and $B$ and we are told that event $B$ has occurred then it doesn't affects our initial believe about event $A$. More formally we can write.\n",
    "\n",
    "$$\n",
    "P(A|B) = P(A)\n",
    "$$\n",
    "\n",
    "thus occurring of event $B$ has no effect on event $A$. But the above definition is not used frequently because it is undefined where $P(B)=0$. So more accurate definition is.\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(A) \\; P(B) \\tag{multiplication rule}\n",
    "$$\n",
    "\n",
    "If the above identity holds for any events then the events are said to be independent. Following identity also work on a sequence of independent events.\n",
    "\n",
    "$$\n",
    "P(A_1 \\cap A_2 \\cap A_3 \\cap A_4) = P(A_1) \\; P(A_2) \\; P(A_3) \\; P(A_4)\n",
    "$$\n",
    "\n",
    "## Independence vs Disjoint events.\n",
    "\n",
    "\n",
    "![Independence vs Disjoint](/static/img/notes/mathematics/intro-probability/independence_vs_disjoint.png)\n",
    "\n",
    "Consider the above events, are these events independent? \n",
    "\n",
    "These events are disjoint but not independent because if we know that event $A$ has occurred then we are for sure that event $B$ has not occurred so both of the events are dependent on each other. Thus disjoint sets are not same as independent sets.\n",
    "\n",
    "## Conditional independence.\n",
    "\n",
    "Some events may become independent upon conditioning and some independent events might not remain independent after conditioning. Conditional independence is similar to that of normal independence with conditioning.\n",
    "\n",
    "$$\n",
    "P(A \\cap B | C) = P(A|C) \\; P(B|C)\n",
    "$$\n",
    "\n",
    "So to verify if a set of events is still independent after conditioning we should find the probability of each event after conditioning and the verify if the independence identity stills holds.\n",
    "\n",
    "## Independence vs Pairwise independence\n",
    "\n",
    "When more than two events are in consideration, then the event can be either all together independent of pair wise independent. For example,\n",
    "\n",
    "Let say we have an experiment of flipping a fair coin twice. And let there be three events as follows.\n",
    "\n",
    "**Event $A$**: First toss is head.\n",
    "\n",
    "**Event $B$**: Second toss is head.\n",
    "\n",
    "**Event $C$**: First and second toss gives same result.\n",
    "\n",
    "Now in this case our sample space is $\\{ HH, HT, TH, TT \\}$. So, here event $A$ and $B$ are pair wise independent, i.e knowing event $A$ has occurred doest changes our believe of event $B$. Similarly, event $A$ and $C$ are pair wise independent and event $B$ and $C$ are pair wise independent. But if we take all the three event together then these went are not independent because if we know that event $A$ and event $B$ has occurred then we are sure that event $C$ has occurred i.e $P(C) = 1$.\n",
    "\n",
    "We can prove that mathematically as follows.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(C) &= \\frac{1}{2} \\\\\n",
    "P(C \\cap A) &= \\frac{1}{4} \\\\\n",
    "P(A \\cap B \\cap C)  &= \\frac{1}{4} \\\\\n",
    "P(C | A \\cap B) &= 1 \\\\\n",
    "\\therefore P(C) &\\neq P(C | A \\cap B)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus following independence identity doesn't hold true.\n",
    "\n",
    "$$\n",
    "P(A \\cap B \\cap C) \\neq P(A) \\; P(B) \\; P(C)\n",
    "$$\n",
    "\n",
    "Thus pair wise independence doesn't imply independent event, pair wise independent events must be independent together.\n",
    "\n",
    "\n",
    "# Combinatorics\n",
    "\n",
    "Combinatorics is an area of mathematics primarily concerned with counting. Sometimes finding out the probability of an event is skimpily as matter of counting the number of possibilities.\n",
    "\n",
    "## Permutation\n",
    "\n",
    "Imagine a list of alphabets from A-Z, which are in total 26 characters. And we are to selected 5 characters from the list. Permutation gives us the total number of combination of 5 characters that we can make from the list of all 26 characters. Permutation can be defined as picking up the number of item from a large pool of items where the position of the item doesn't matter.\n",
    "\n",
    "There are two formulae depending upon where we are allow the repeat the selected items while choosing new item or not.\n",
    "\n",
    "### With Repetition\n",
    "\n",
    "If repetition is allowed then we can that we have 26 chooses for our first character and 26 for our second and so and so forth. So the total number of permutation possible with repetition can be given as.\n",
    "\n",
    "$$\n",
    "26 * 26 * 26 * 26 * 26\n",
    "$$\n",
    "\n",
    "We can formularize the definition as follows. Let $n$ be the total number of items available for selection and let $r$ be the number of items we want to make combinations of, so the formulae can be written as.\n",
    "\n",
    "$$\n",
    "n^r\n",
    "$$\n",
    "\n",
    "\n",
    "### Without Repetition\n",
    "\n",
    "If repetition is not allowed. Then for our first character we have 26 choices and then 25 for second and 24 for third etc. So number of permutation without repetition is.\n",
    "\n",
    "$$\n",
    "26 * 25 * 24 * 23 * 22\n",
    "$$\n",
    "\n",
    "Formula for the same can be written as follows.\n",
    "\n",
    "$$\n",
    "\\frac{n!}{(n - r)!}\n",
    "$$\n",
    "\n",
    "## Combinations\n",
    "\n",
    "Combination is same as permutation but here the position of the element matter. For example there \"ABCD\" is difference from \"BACD\" because position of \"A\" and \"B\" are different.\n",
    "\n",
    "### Without Repetition\n",
    "\n",
    "Without repetition the formula for combination is given as follows.\n",
    "\n",
    "$$\n",
    "\\frac{n!}{r! (n-r)!}\n",
    "$$\n",
    "\n",
    "Combination is denoted by $\\binom{n}{r}$. Thus,\n",
    "\n",
    "$$\n",
    "\\binom{n}{r} = \\frac{n!}{r! (n-r)!}\n",
    "$$\n",
    "\n",
    "### With Repetition\n",
    "\n",
    "If repetition is allowed then we use the following formula.\n",
    "\n",
    "$$\n",
    "\\frac{(r + n - 1)}{r!(n - 1)!}\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "note_info": {
   "description": "Basic probability axioms and Random Variables",
   "image": "static/img/notes/mathematics/intro-probability/logo.jpg",
   "slug": "intro-probability",
   "title": "Introduction To Probability"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "344px",
    "width": "555px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
